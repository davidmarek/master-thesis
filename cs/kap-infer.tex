% !TEX root = prace.tex
\chapter{Bayesovské sítě a inference}

V této kapitole představíme Bayesovské sítě, grafický model pro efektivní reprezentaci pravděpodobnostních rozdělení a nezávislostí mezi náhodnými proměnnými.
Bayesovská síť zároveň vytváří koncept pro inferenci, tedy zodpovídání dotazů nad proměnnými v síti.
Ukážeme si několik přístupů k inferenci, nejprve naivní výpočet vycházející přímo z definice.
Následně využijeme vlastností sítě a konceptů dynamického programování pro jeho zlepšení.
Analýzou složitosti exaktní inference dojdeme k závěru, že pro větší a komplexnější modely bude třeba se uchýlit k aproximacím.

Nejprve aproximujeme sdruženou pravděpodobnostní distribuci součinem marginálních distribucí a představíme Loopy Belief Propagation algoritmus.
Stále můžeme použít pouze diskrétní pravděpodobnostní distribuce se známými parametry.
Pro učení parametrů lze použít Expectation Maximization metodu, pro dialogové systémy je ovšem těžké získat dostatek učících dat.
Nakonec se dostaneme k metodě Expectation Propagation, která je zobecněním LBP a je tedy možné ji použít pro libovolné rozdělení.
Díky ní budeme schopní vytvořit generativní model pro aktualizaci dialogového stavu, který bude pracovat stejně jako LBP, ale bude schopen adaptace.

\section{Bayesovské sítě}

Bayesovské sítě jsou pravděpodobnostní grafický model, který využívá podmíněných nezávislostí pro úspornou reprezentaci sdružené pravděpodobnosti.
Bayesovská sít je orientovaný acyklický graf, jeho vrcholy jsou náhodné proměnné a hrany odpovídají přímé závislosti jednoho uzlu na druhý.
Pro každou náhodnou proměnnou v síti platí, že její pravděpodobnost je jednoznačně určena jejími rodiči v grafu.
Podmíněná pravděpodobnostní distribuce (CPD) proměnné $X$ popisuje pravděpodobnost proměnné $X$ dáno její rodiče, $P(X \mid parents(X))$.
Pokud proměnná nemá žádná rodiče, pak její podmíněná pravděpodobnostní distribuce je ekvivalentní marginální pravděpodobnostní distribuci.

Příklad Student~\cite{koller2009probabilistic}: firma zvažuje, zda-li přijme studenta.
Firma chce přijímat chytré studenty, ale nesmí je testovat na inteligenci (I) přímo.
Má však výsledek studentových SAT testů, které ale nemusí stačit pro správné zhodnocení inteligence.
Požadují tak tedy i doporučení (D) od jednoho z učitelů.
Učitel studentovi napíše doporučující dopis na základě známky (Z), kterou student získal v jeho předmětu.
Předměty se ovšem liší v obtížnosti (O) a tak je studentova známka v předmětu závislá nejen na jeho inteligenci, ale také na obtížnosti předmětu.
Grafický model reprezentující tento problém je vyobrazen na obrázku~\ref{fig:student}.
\begin{figure}
\begin{center}
\begin{tikzpicture}

\matrix[row sep=0.75cm, column sep=1.2cm]
{
    \node[latent]       (O)     {O};
    && \node[latent]    (I)     {I};
    \\
    &\node[latent]      (Z)     {Z};
    &&\node[latent]     (S)     {SAT};
    \\
    &\node[latent]      (D)     {D};
    \\
};

\edge{O}{Z}
\edge{I}{Z}
\edge{I}{S}
\edge{Z}{D}

\end{tikzpicture}
\end{center}
\label{fig:student}
\caption{Bayesovská síť pro příklad se studentem.}
\end{figure}

V tomto modelu je několik nezávislostí. Obtížnost předmětu a inteligence studenta jsou zjevně nezávislé.
Studentova známka z předmětu je závislá na obtížnosti předmětu a inteligenci studenta, ale je podmíněně nezávislá na jeho výsledku ze SAT, dáno studentova inteligence.
Konečně doporučení, které student obdrží, je podmíněně nezávislé na všech ostatních proměnných, dáno studentova známka.

Sdruženou nezávislot tohoto modelu lze zapsat ve formě podmíněných pravděpodobnostních distribucí s pomocí řetízkového pravidla.
\begin{equation}
P(O, I, Z, S, D) = P(D \mid Z) P(Z \mid O, I) P(SAT \mid I) P(O) P(I)
\end{equation}

Předpokládejme, že obtížnost předmětu, inteligence studenta, doporučující dopis a výsledek SAT jsou binární proměnné.
Známka z předmětu pak je ternární proměnná.
Pokud bychom zapsali sdruženou pravděpodobnost ve formě tabulky, tak se dostaneme k 48 položkám.
Díky rozdělení do podmíněných pravděpodobnostních rozložení, které nám bayesovská síť poskytuje, se dostáváme k $2 + 2 + 12 + 4 + 6 = 26$ položkám.
Tedy i v tomto jednoduchém modelu dochází k značné úspoře.

\section{Inference v Bayesovských sítích}

Bayesovské sítě reprezentují pravděpodobnostní model a umožňují nám nad ním provádět dotazy.
Můžeme se například ptát na marginální pravděpodobnost jednotlivých proměnných. 
Tu získáme marginalizací sdružené pravděpodobnosti, pokud vezmeme příklad se studentem a budeme chtít znát marginální pravděpodobnost známek, musíme vysčítat všechny ostatní proměnné.

\begin{equation}
P(Z) = \sum_{O, I, S, D} P(D \mid Z) P(Z \mid O, I) P(SAT \mid I) P(O) P(I)
\end{equation}

Další a asi nejčastější dotaz nastává, pokud některé náhodné proměnné pozorujeme. 
Pak chceme znát pravděpodobnost jiných proměnných dáno naše pozorování, $P(\vec{X} \mid \vec{E} = \vec{e})$, kde $\vec{X}$ jsou dotazované proměnné, $\vec{E}$ jsou pozorované proměnné a $\vec{e}$ jsou pozorované hodnoty.
Z definice podmíněné pravděpodobnosti dostáváme

\begin{equation}
P(\vec{X} \mid \vec{E} = \vec{e}) = \frac{P(\vec{X}, \vec{E} = \vec{e})}{P(\vec{E} = \vec{e})}
\end{equation}

Každou instanci jmenovatele $P(\vec{X}, \vec{E} = \vec{e})$ jde spočítat sumou sdružených pravděpodobností s ohodnoceními proměnných, které jsou kompatibilní s pozorováním a aktuální instancí. 
Pokud počítáme instanci $P(\vec{X} = \vec{x}, \vec{E} = \vec{e})$, pak získáme výsledek marginalizací všech proměnných, kromě $\vec{X}$ a $\vec{E}$, které jsou fixovány.
Pokud tedy množinu všech proměnných bez $\vec{X}$ a $\vec{E}$ označíme $\mathcal{W} = \mathcal{X} - \vec{X} - \vec{E}$, pak pravděpodobnost dané instance je

\begin{equation}
P(\vec{X} = \vec{x}, \vec{E} = \vec{e}) = \sum_{\vec{w}} P(\vec{x}, \vec{e}, \vec{w})
\end{equation}

Pro výpočet normalizační konstanty $P(\vec{E})$ musíme opět marginalizovat sdruženou pravděpodobnost, anebo si můžeme povšimnout, že platí
\begin{equation}
P(\vec{E} = \vec{e}) = \sum_{\vec{x}} P(\vec{x}, \vec{e})
\end{equation}
a tedy můžeme použít už vypočítané hodnoty.

\subsection{Exaktní inference}

V předchozí části jsme viděli, že pomocí definice podmíněné pravděpodobnosti a marginalizace sdružené pravděpodobnosti lze najít odpověď na libovolný dotaz. 
Nyní si ukážeme algoritmus, který využívá struktury Bayesovské sítě pro inferenci a navíc díky metodám dynamického programování umožňuje samotný výpočet urychlit.
Nakonec ovšem zjistíme, že pro velké sítě, které nás většinou zajímají nejvíce, nám přesná inference nebude stačit a musíme se uchýlit k aproximacím.

Začneme s inferencí v jednoduchém modelu $A \rightarrow B \rightarrow C \rightarrow D$.
Sdružená pravděpodobnost $P(A, B, C, D)$ je součinem jednotlivých podmíněných pravděpodobnostních distribucí
\begin{equation}
P(A, B, C, D) = P(D \mid C) P(C \mid B) P(B \mid A) P(A)
\end{equation}

Pokud nyní budeme chtít spočítat marginální distribuci $D$, tak musíme marginalizovat všechny ostatní proměnné
\begin{equation}
P(D) = \sum_{A, B, C} P(D \mid C) P(C \mid B) P(B \mid A) P(A)
\end{equation}

Můžeme si povšimnout, že spousta členů se bude počítat vícekrát.
Využitím metod dynamického programování a přeuspořádáním sum si můžeme mezivýsledky uložit a použít vícekrát.
\begin{equation}
P(D) = \sum_C P(D \mid C) \sum_B P(C \mid B) \sum_A P(B \mid A) P(A)
\end{equation}

Při výpočtu pak nejprve spočítáme $\psi_1(A, B) =  P(B \mid A) P(A)$,  pak vysčítáme proměnnou $A$ a získáme $\tau_1(B) = \sum_A \psi_1(A, B)$.
Pokračujeme obdobně
\begin{align}
    \psi_2(B, C) &= P(C \mid B) \tau_1(B) \\
    \tau_2(C) &= \sum_B \psi_2(B, C)
\end{align}
A nakonec spočítáme finální marginální pravděpodobnost
\begin{align}
    \psi_3(D, C) &= P(D \mid C) \tau_2(C) \\
    P(D) &= \sum_C \psi_3(D, C)
\end{align}

\begin{definice}
Nechť $\mathcal{X}$ je množina náhodných proměnných. 
Potom definujeme faktor $\phi$ jako zobrazení z $Val(\mathcal{X})$ do $\mathbb{R}$. Faktor je nezáporný, pokud všechny jeho obrazy jsou nezáporné. Množina proměnných $\mathcal{X}$ je doménou faktoru a značíme ji jako $Dom(\phi)$.
\end{definice}

Faktor, jehož doménu tvoří diskrétní proměnné, si můžeme představit jako tabulku, která obsahuje jednu hodnotu pro každé možné ohodnocení proměnných z domény.

\begin{definice}
Nechť $\vec{X}, \vec{Y}, \vec{Z}$ jsou tři disjunktní množiny náhodných proměnných.
Nechť $\phi_1(\vec{X}, \vec{Y})$ a $\phi_2(\vec{Y}, \vec{Z})$ jsou faktory.
Definujeme součin faktorů $\phi_1 \times \phi_2$ jako faktor $\psi: Val(\vec{X}, \vec{Y}, \vec{Z}) \rightarrow \mathbb{R}$ následovně:
\begin{equation*}
\psi(\vec{X}, \vec{Y}, \vec{Z}) = \phi_1(\vec{X}, \vec{Y}) \cdot \phi_2(\vec{Y}, \vec{Z})
\end{equation*}
\end{definice}

Násobíme prvky, které mají stejné ohodnocení společných proměnných $\vec{Y}$.
Stejný princip použijeme pro všechny matematické operace.

\begin{definice}
Nechť $\vec{X}$ je množina náhodných proměnných a $Y \not\in \vec{X}$ náhodná proměnná. 
Nechť $\phi(\vec{X}, Y)$ je faktor.
Definujeme marginalizaci $Y$ v $\phi$, značenou $\sum_Y \phi$, jako faktor $\psi$ s doménou $\vec{X}$ takový, že
\begin{equation*}
    \psi(\vec{X}) = \sum_Y \phi(\vec{X}, Y)
\end{equation*}
Této operaci také říkáme vysčítání $Y$ ve $\phi$.
\end{definice}

Faktory se při počítání chovají jako čísla, všechny operace probíhají po prvcích, pro které je ohodnocení náhodných proměnných z průniku domén faktorů stejné.
Proto platí komutativita $\phi_1 \cdot \phi_2 = \phi_2 \cdot \phi_1$ a $\sum_X \sum_Y \phi = \sum_Y \sum_X \phi$.
Dále platí asociativita součinu $(\phi_1 \cdot \phi_2) \cdot \phi_3 = \phi_1 \cdot (\phi_2 \cdot \phi_3)$.
Nakonec můžeme vyměnit sumu a součin, pokud $X \not\in Dom(\phi_1)$, potom $\sum_X (\phi_1 \cdot \phi_2) = \phi_1 \sum_X \phi_2$.

Sdruženou pravděpodobnost z minulého příkladu tedy můžeme přepsat do formy faktorů.
\begin{equation}
    P(A, B, C, D) = \phi_A \cdot \phi_B \cdot \phi_C \cdot \phi_D
\end{equation}

Opět se pokusíme spočítat marginální pravděpodobnost proměnné $D$.
\begin{align}
P(D) &= \sum_C \sum_B \sum_A \phi_A \phi_B \phi_C
\\
&= \sum_C 
	\phi_D \cdot 
	\left( 
		\sum_B 
			\phi_C \cdot 
			\left( 
				\sum_A 
					\phi_A \cdot \phi_B
			\right)
	\right)
\end{align}

Přesuny sum můžeme provést díky doméně jednotlivých faktorů.
Faktory $\phi_C$ a $\phi_D$ neobsahují proměnnou $A$ a tedy je můžeme vytknout před sumu přes $A$.
Stejně tak faktor $\phi_D$ neobsahuje proměnnou $B$ a opět jej můžeme vytknout před sumu přes $B$.
Tyto úpravy můžeme provádět v libovolném pořadí, pokud vždy platí, že vysčítáme proměnnou $X$ až poté, co spolu vynásobíme všechny faktory, které ji obsahují.

V obecnosti vždy počítáme výraz, který je ve tvaru
\[
\sum_X \prod_{\phi \in \Phi} \phi.
\]

Z tohoto také vychází název pro tuto metodu: sum-product.
Jednoduchý algoritmus pro exaktní inferenci využívající tuto metodu se nazývá eliminace proměnných.
Základní myšlenka je, že máme dán seznam náhodných proměnných v pořadí, v jakém se mají eliminovat.
Pro eliminaci proměnné je třeba nejprve vynásobit všechny faktory, které ji obsahují a následně ji vysčítat.
Tak získáme faktor, který už tuto proměnnou neobsahuje, tedy jsme ji eliminovali.
Eliminace proměnných je popsána v algoritmu~\ref{alg:ve}.

\begin{algorithm}[H]
\caption{Eliminace proměnných}
\label{alg:ve}
\begin{algorithmic}
\Function{Sum-Product-VE}{$\Phi$, $\vec{X}$, $\prec$}
\State{$\Phi$ množina všech faktorů.} 
\State{$\vec{X}$ množina náhodných proměnných, které mají být eliminovaný.}
\State{$\prec$ pořadí proměnných, v jakém mají být eliminovány.}
\State

\State Nechť $X_1, \dots, X_k$ je seřazení proměnných z $\vec{X}$, t.ž. $X_i \prec X_j \Leftrightarrow i < j$.
\For{$i = 1 \dots k$}
	\State $\Phi \gets$ Sum-Product-Eliminate-Var($\Phi$, $Z_i$)
\EndFor
\State $\phi^* \gets \prod_{\phi \in \Phi} \phi$
\State \Return $\phi^*$
\EndFunction
\State
\Function{Sum-Product-Eliminate-Var}{$\Phi$, $X$}
\State{$\Phi$ množina všech faktorů.}
\State{$X$, proměnná, která má být eliminována.}
\State

\State $\Phi^\prime \gets \{\phi \in \Phi: X \in Dom(\phi)\}$
\State $\Phi^{\prime \prime} \gets \Phi - \Phi^\prime$
\State $\psi \gets \prod_{\phi \in \Phi^\prime} \phi$
\State $\tau \gets \sum_X \psi$
\State \Return $\Psi^{\prime\prime} \bigcup \{\tau\}$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{theorem}
Nechť $\vec{X}$ je množina náhodných proměnných, nechť $\Phi$ je množina faktorů, t.ž. pro každé $\phi \in \Phi$, $Dom(\phi) \subseteq \vec{X}$.
Nechť $\vec{Y} \subset \vec{X}$ je množina dotazovaných náhodných proměnných a nechť $\vec{Z} = \vec{X} - \vec{Y}$.
Pak pro každé seřazení $\prec$ nad $\vec{Z}$, Sum-Product-VE($\Phi$, $\vec{Z}$, $\prec$) vrátí faktor $\phi^*(\vec{Y})$ takový, že
\[
\phi^*(\vec{Y}) = \sum_Z \prod_{\phi \in \Phi} \phi
\]
\end{theorem}

Nyní provedeme analýzu algoritmu eliminace proměnných.
Předpokládejme, že na vstupu je $n$ proměnných.
Bayesovská síť obsahuje pro každou proměnnou jeden faktor.
Pro jednoduchost budeme předpokládat, že algoritmus bude eliminovat všechny proměnné.
Běh algoritmu se skládá z jednotlivých eliminačních kroků, při kterých je vždy eliminována jedna proměnná.

Při jednom eliminačním kroku je vybrána proměnná $X_i$, všechny faktory, které ji obsahují jsou pronásobeny a vytvoří jeden velký faktor $\psi_i$, proměnná $X_i$ je pak vysčítána z tohoto faktoru.
Počet operací pro jeden eliminační krok tedy závisí na velikosti faktoru $\psi_i$, označme ji $N_i$.
Maximum z velikostí faktorů označme $N_{max} = max_i N_i$.

Nyní se zaměříme na počet násobení.
Celkem vznikne $n+m$ faktorů, kde $m$ je počet faktorů, které vznikly vysčítáním proměnné.
Každý z těchto faktorů je zahrnut do součinu pouze jednou, pokud je eliminována nějaká proměnná, kterou obsahuje.
Cena násobení faktorů pro vznik $\psi_i$ je nejvýše $N_i$.
Celkový počet násobení tedy bude nejvýše $(n+m)N_{max}$ což je $\mathcal{O}(nN_{max})$.

Pokud $k$ je maximum z velikostí domén proměnných, pak velikost faktoru obsahujícího $n$ proměnných může být až $k^n$.
Složitost eliminace proměnných je tedy dominována velikostí faktorů, které vznikají při výpočtu a je exponenciální.
Navíc bylo dokázáno, že výběr nejlepšího pořadí proměnných pro eliminaci je NP těžký~\cite{arnborg1987complexity}.

\subsection{Posílání zpráv ve faktor grafu}

Algoritmy exaktní inference naráží při reálném použití na příliš velkou složitost násobení faktorů.
Hlavním problémem je velikost sdružené pravděpodobnosti, která roste exponenciálně s počtem náhodných proměnných.
Většinou nás ovšem zajímá marginální pravděpodobnost jedné nebo jen mála proměnných.
Je tedy zbytečné počítat celou sdruženou pravděpodobnost, abychom z ní pak vysčítali většinu proměnných.
Řešení se nabízí ve formě faktorizace sdružené pravděpodobnosti.

\begin{equation*}
    P(X_1, \dots, X_n) = \prod_i P(X_i)
\end{equation*}

Pro výpočet s faktorizovanou distribucí si zavedeme novou datovou strukturu, tzv. faktor graf.
Faktor graf je bipartitní graf, kde jednu partitu tvoří faktory a druhou partitu tvoří náhodné proměnné.
Hrany ve faktor grafu vedou vždy mezi proměnnou a faktorem, který ji obsahuje.

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}
    
\matrix[row sep=0.75cm, column sep=1.2cm]
{
    \node[latent]   (X1)    {$X_1$};
    &
    \factor         {fa}    {$f_a$}{}{};
    &
    \node[latent]   (X2)    {$X_2$};
    &
    \factor         {fb}    {$f_b$}{}{};
    &
    \node[latent]   (X3)    {$X_3$};
    \\
    &&
    \factor         {fc}    {left:$f_c$}{}{};
    \\
    &&
    \node[latent]   (X4)    {$X_4$}{}{};
    \\
};
\edge[-]{X1,X2} {fa}
\edge[-]{X3,X2} {fb}
\edge[-]{X2,X4} {fc}

\end{tikzpicture}
\end{center}
\caption{Příklad faktor grafu se třemi náhodnými proměnnými $X_1, X_2, X_3$ a třemi faktory $f_a, f_b, f_c$.}
\end{figure}

Nejprve začneme s inferencí na stromech.
Pokud zafixujeme jednu náhodnou proměnnou $X$ ve faktor grafu, pak sdruženou pravděpodobnost můžeme spočítat jako
\begin{equation}
    P(\vec{X}) = \prod_{s \in ne(X)} F_s(X, \vec{X}_s),
\label{eq:fs}
\end{equation}
kde $ne(X)$ jsou faktory obsahující proměnnou $X$ (tedy sousedi ve faktor grafu), $F_s$ je součin všech faktorů v podstromu určeném faktorem $f_s$ a $\vec{X}_s$ je množina všech proměnných v daném podstromu.

Pro výpočet marginální pravděpodobnosti $X$ substitujeme~(\ref{eq:fs}) do výpočtu marginální pravděpodobnosti ze sdružené a po výměně sumy a produktu dostaneme
\begin{align}
P(X) &= \prod_{s \in ne(X_i)} \sum_{\vec{X}_s} F_s(X, \vec{X}_s)
\\
&= \prod_{s \in ne(X)} \mu_{f_s \rightarrow X}(X)
\label{eq:margx}
\end{align}

Zavedli jsme funkce
\begin{equation}
    \mu_{f_s \rightarrow X} \equiv \sum_{\vec{X}_s} F_s(X, \vec{X}_s),
\label{eq:defmsgfx}
\end{equation}
které můžeme nazývat zprávami z faktoru $f_s$ do proměnné $X$.

Každé $F_s(X, \vec{X}_s)$ je popsáno faktor grafem a tedy může být znova faktorizováno.
Namísto proměnné $X$ nyní vezmeme faktor $f_s$.
Náhodné proměnné sousedící s faktorem $f_s$ bez $X$ si označíme $X_1, \dots, X_M$.
Součin faktorů v podstromech určených těmito proměnnými označíme $G_i(X_i, \vec{X}_{si})$.
Faktor $F_s(X, \vec{X}_s)$ tedy můžeme přepsat jako
\begin{equation}
F_s(X, \vec{X}_s) = f_s(X, X_1, \dots, X_M) G_1(X_1, \vec{X}_{s1}), \dots, G_M(X_M, \vec{X}_{sM})
\end{equation}

Pokud substitujeme přepsaný faktor $F_s(X, \vec{X}_s)$ do definice zprávy z faktoru, dostaneme
\begin{align}
\mu_{f_s \rightarrow X}(X) &=
    \sum_{X_1} \dots \sum_{X_M}
        f_s(X, X_1, \dots, X_M)
        \prod_{m \in ne(f_s) \backslash X}
            \sum_{\vec{X}_{sm}}
                G_m(X_m, \vec{X}_{sm})
\\
&= \sum_{X_1} \dots \sum_{X_M}
    f_s(X, X_1, \dots, X_M)
    \prod_{m \in ne(f_s) \backslash X}
        \mu_{X_m \rightarrow f_s}(X_m)
\label{eq:mfsx}
\end{align}

Zavedli jsme další funkce 
\begin{equation}
    \mu_{X_m \rightarrow f_s}(X_m) \equiv \sum_{\vec{X}_{sm}} G_m(X_m, \vec{X}_{sm}),
\label{eq:defmsgxf}
\end{equation}
které budeme nazývat zprávami z proměnné $X_m$ do faktoru $f_s$.

Z rovnice~\ref{eq:margx} vidíme, že marginální pravděpodobnost proměnné vypočítáma jako součin zpráv ze všech okolních faktorů.
Každou z těchto zpráv můžeme spočítat jako součin faktoru a zpráv přicházejících z proměnných, které s tímto faktorem sousedí, kromě proměnné, které chceme zprávu posílat. Zbývá nám tedy zjistit v jakém tvaru jsou zprávy z proměnných do faktoru.

Stejně jako u $F_s(X, \vec{X}_s)$ nám tady $G_m(X_m, \vec{X}_{sm})$ definuje podgraf faktor grafu. 
V kořeni tohoto podgrafu leží proměnná $X_m$ a tím se dostáváme na už známý případ.
Budeme ignorovat faktor $f_s$, protože neleží v podgrafu určeném $G_m(X_m, \vec{X}_{sm})$, a pak 
\begin{equation}
    G_m(X_m, \vec{X}_{sm}) = \prod_{l \in ne(X_m) \backslash f_s} F_l(X_m, \vec{X}_{ml})
\end{equation}
Přepsáno ve formě zpráv
\begin{align}
\mu_{X_m \rightarrow f_s}(X_m)
&= \prod_{l \in ne(X_m) \backslash f_s}
    \sum_{\vec{X}_{ml}}
        F_l(X_m, \vec{X}_{ml})
\\
&= \prod_{l \in ne(X_m) \backslash f_s}
    \mu_{f_l \rightarrow X_m}(X_m)
\end{align}
Zpráva z náhodné proměnné je tedy součinem zpráv ze všech ostatních faktorů.

Zprávy tedy dokážeme počítat rekurzivně, chybí nám ovšem pravidla pro zprávy z uzlů, které jsou listy.
V případě faktoru je odchozí zpráva ekvivalentní faktoru.
\begin{equation}
    \mu_{f \rightarrow X}(X) = f(X)
\end{equation}
V případě náhodné proměnné je odchozí zpráva 
\begin{equation}
    \mu_{X \rightarrow f}(X) = 1
\end{equation}
Pro pozorovanou proměnnou je zpráva vždy rovna pozorované hodnotě, bez ohledu na sousední faktory.

\subsection{Belief Propagation}

Algoritmus exaktní inference na stromech s pomocí posílání zpráv se nazývá belief propagation~\cite{pearl1988probabilistic}.
Zpráva z vrcholu faktor grafu může být poslána do jiného vrcholu, až když byly obdrženy zprávy ze všech ostatních vrcholů.
Jakmile vrchol obdržel zprávy ze všech vrcholů, tak lze spočítat jeho marginální pravděpodobnost.
Strom vždy můžeme zakořenit v nějaké náhodné proměnné a posílat zprávy z listů do kořene.
Kořen pak obdrží všechny zprávy ze všech sousedních faktorů a tedy je možné spočítat jeho marginální pravděpodobnost.
Tomuto se říká dopředný krok propagace.

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}

\matrix[row sep=0.75cm, column sep=1.2cm]
{
    \node[latent]   (X1)    {$X_1$};
    &
    \factor         {fa}    {$f_a$}{}{};
    &
    \node[latent]   (X2)    {$X_2$};
    &
    \factor         {fb}    {$f_b$}{}{};
    &
    \node[latent]   (X3)    {$X_3$};
    \\
    &&
    \factor         {fc}    {left:$f_c$}{}{};
    \\
    &&
    \node[latent]   (X4)    {$X_4$}{}{};
    \\
};
\edge{X1}{fa}
\edge{fa}{X2}
\edge{X4}{fc}
\edge{fc}{X2}
\edge{X2}{fb}
\edge{fb}{X3}

\end{tikzpicture}
\end{center}
\caption{Směr posílání zpráv pro strom zakořeněný ve vrcholu $X_3$ v dopředném kroce.}
\end{figure}

Belief propagation algoritmus tedy umožňuje na stromech spočítat marginální pravděpodobnost jedné proměnné s linárním počtem poslaných zpráv.
Při rozšíření na spočítání marginální pravděpodobnosti všech proměnných není třeba algoritmus pouštět $n$-krát.
Stačí si uvědomit, že všem vrcholům chybí pouze zpráva od faktoru na cestě ke kořenu.
A my můžeme z kořene poslat zprávy zpět k listům hned, jak obdržíme všechny příchozí zprávy.
Této části se říká zpětný krok propagace.

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}

\matrix[row sep=0.75cm, column sep=1.2cm]
{
    \node[latent]   (X1)    {$X_1$};
    &
    \factor         {fa}    {$f_a$}{}{};
    &
    \node[latent]   (X2)    {$X_2$};
    &
    \factor         {fb}    {$f_b$}{}{};
    &
    \node[latent]   (X3)    {$X_3$};
    \\
    &&
    \factor         {fc}    {left:$f_c$}{}{};
    \\
    &&
    \node[latent]   (X4)    {$X_4$}{}{};
    \\
};
\edge{fa}{X1}
\edge{X2}{fa}
\edge{fc}{X4}
\edge{X2}{fc}
\edge{fb}{X2}
\edge{X3}{fb}

\end{tikzpicture}
\end{center}
\caption{Směr posílání zpráv pro strom zakořeněný ve vrcholu $X_3$ ve zpětném kroce.}
\end{figure}

Po propagaci všech zpráv až k listům už každá proměnná získala zprávy od všech sousedních faktorů a tedy je možné spočítat marginální pravděpodobnost všech proměnných.

\subsection{Loopy Belief Propagation}

Algoritmus Belief Propagation funguje pro inferenci na stromech.
Hlavní důvod proč nelze použít Belief Propagation na obecných grafech je, že můžeme narazit na cyklus v grafu, což znamená, že žádný z vrcholů v tomto cyklu nebude nikdy mít dostatek příchozích zpráv, aby mohl nějakou zprávu odeslat.

Algoritmus Loopy Belief Propagation řeší tento problém relaxací podmínky na příchozí zprávy.
Pro odeslání není třeba znát příchozí zprávy ze všech sousedních vrcholů, kromě toho, kterému je zpráva určena.
Chybějící zprávy jsou nastaveny na jedničku.
Loopy Belief Propagation je iterativní algoritmus.
V grafu nemusí existovat vrchol, který může posílat zprávu k nějakému ze svých sousedů.
Je tedy třeba vybrat vrchol podle nějaké strategie a z něj poslat zprávy do všech sousedních vrcholů.
V další iteraci je pak vybrán zase jiný vrchol, který bude posílat zprávy.
Iterace končí ve chvíli, kdy se už nemění marginální pravděpodobnosti proměnných.

Vzhledem k tomu, že posílané zprávy už neodpovídají skutečným faktorům, je důležitá otázka, zda-li Loopy Belief Propagation vůbec nalezne správné marginální pravděpodobnosti.
Existují podmínky za kterých algoritmus bude konvergovat~\cite{tatikonda2002loopy}.
V obecném případě ovšem může algoritmus konvergovat ke špatným pravděpodobnostem, anebo nemusí konvergovat vůbec a pak dochází k oscilacím.
Pokud algoritmus nekonverguje ke správným pravděpodobnostem, tak není ani možné se k nim přiblížit nebo je odvodit z oscilací~\cite{murphy1999loopy}.
V praxi ovšem k problémům většinou nedochází a inference konverguje v rozumném čase.

\begin{algorithm}
\caption{Loopy Belief Propagation}
\label{alg:lbp}
\begin{algorithmic}
\Function{LBP}{$F$, $S$}
\State{$F$ -- faktor graf}
\State{$S$ -- strategie}
\State

\State{$\textsc{Init-Factor-Graph}(F)$}
\Repeat
    \For{vrchol $v \in F$ vybraný podle strategie $S$}
        \For{soused $n$ vrcholu $v$}
            \If{$v$ je faktor}
                \State{$\mu_{v \rightarrow n}(n) \gets \textsc{Message-To-Var}(v, n)$}
            \Else
                \State{$\mu_{v \rightarrow n}(v) \gets \textsc{Message-To-Factor}(v, n)$}
            \EndIf
        \EndFor
    \EndFor
\Until{konvergence}

\For{každá proměnná $X$}
    \State{$P(X) = \prod_{f \in ne(X)} \mu_{f \rightarrow X}(X)$}
\EndFor
\EndFunction

\State

\Function{Init-Factor-Graph}{$F$}
\State{$F$ -- faktor graf}
\State

\For{každou proměnnou $X \in F$}
    \For{sousední faktor $f$}
        \State{$\mu_{X \rightarrow f}(X) \gets 1$}
        \State{$\mu_{f \rightarrow X}(X) \gets 1$}
    \EndFor
\EndFor
\EndFunction

\State

\Function{Message-To-Var}{$f$, $v$}
\State{$f$ -- zdrojový faktor}
\State{$v$ -- cílová proměnná}
\State

\State{$\vec{X} \gets \text{Dom}(f)$}
\State{$\mu_{f \rightarrow v}(v) \gets \sum_{\vec{X} \backslash v} f(\vec{X}) \prod_{u \in ne(f) \backslash v} \mu_{u \rightarrow f}(u)$}
\EndFunction

\State

\Function{Message-To-Factor}{$v$, $f$}
\State{$v$ -- zdrojová proměnná}
\State{$f$ -- cílový faktor}
\State

\State{$\mu_{v \rightarrow f}(v) \gets \prod_{g \in ne(v) \backslash f} \mu_{g \rightarrow v}(v)$ }
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsubsection{Popis LBP}

Popis Loopy Belief Propagation je v algoritmu~(\ref{alg:lbp}).
Při inferenci ve faktor grafu je nejprve třeba inicializovat všechny zprávy.
Posílání zpráv budeme iterovat dokud zprávy nedokonvergují, anebo můžeme nastavit pevný počet iterací.
Pak vybíráme vrcholy a z každého pošleme zprávu do všech okolních.
Způsobem výběru vrcholů se budeme zabývat později.
I kdybychom vybírali vrcholy v náhodném pořadí, tak se můžeme dobrat k výsledku, pouze to bude nejspíš trvat déle.

Poslání zprávy se liší podle toho, zda posíláme z proměnné do faktoru, anebo naopak.
V obou případech vynásobíme příchozí zprávy ze všech sousedních vrcholů, kromě toho, do kterého zprávu posíláme.
Při posílání zprávy z faktoru zprávy vynásobíme faktorem a marginalizujeme všechny proměnné, kromě té, které zprávu posíláme.

Ve faktor grafu se tedy zprávy šíří pouze přes pravděpodobnostní rozdělení jedné proměnné.
To může právě vést k oscilacím anebo konvergenci ke špatným hodnotám. 
Příkladem může být skrytý markovský model se dvěma skrytými binárními proměnnými a pozorováním pro každou skrytou proměnnou.
Pokud je mezi proměnnými závislost XOR, pak nikdy nebudeme pozorovat $(1, 1)$, ale přesto bude každá proměnná konvergovat k rovnoměrnému rozdělení. A tedy sdružená pravděpodobnost pro pozorování $(1, 1)$ dostane nenulovou pravděpodobnost.

\subsection{Strategie výběru vrcholu v LBP algoritmu}

Inference v grafu se může lišit podle typu faktor grafu, ale také podle nároků, které na výsledek máme.
Nejjednodušší metodou pro výběr je nechat pořadí na uživateli algoritmu.
Pro stromy máme speciální strategii, která zaručí konvergenci po jednom dopředném a jednom zpětném kroku propagace.
V dialogových systémech je často používána dynamická bayesovská síť a nás zajímá pravděpodobnost proměnných v poslední vrstvě sítě.
V takovém případě můžeme některé zprávy zanedbat, protože už příliš neovlivní proměnné, které nás zajímají.

\subsubsection{Inference na stromě}

Pro efektivní inferenci je třeba si pro každý vrchol pamatovat, kolik mu chybí zpráv, aby mohl odeslat zprávu.
Pro každý vrchol $v$ s $k$ sousedy je na začátku počet chybějících zpráv $k-1$.
